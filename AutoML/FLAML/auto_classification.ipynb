{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b398e2c6-1d54-407c-9de5-d0affbb9e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"flaml[automl]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1232be6d-d366-4d09-be71-968cd4514f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-14 15:49:40] {1693} INFO - task = classification\n",
      "[flaml.automl.logger: 06-14 15:49:40] {1700} INFO - Data split method: stratified\n",
      "[flaml.automl.logger: 06-14 15:49:40] {1703} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 06-14 15:49:40] {1801} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 06-14 15:49:40] {1911} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2347} INFO - Estimated sufficient time budget=308s. Estimated necessary time budget=7s.\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.0s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.1s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.1s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.1s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.2s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.3s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 7, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.4s,\testimator extra_tree's best error=0.1533,\tbest estimator lgbm's best error=0.0467\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.5s,\testimator rf's best error=0.0867,\tbest estimator lgbm's best error=0.0467\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.5s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.6s,\testimator rf's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.7s,\testimator rf's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2394} INFO -  at 0.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:40] {2221} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2394} INFO -  at 0.8s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2221} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2394} INFO -  at 0.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2221} INFO - iteration 17, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-14 15:49:41] {2394} INFO -  at 0.9s,\testimator extra_tree's best error=0.1533,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2221} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2394} INFO -  at 1.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2221} INFO - iteration 19, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2394} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.0222,\tbest estimator xgb_limitdepth's best error=0.0222\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2630} INFO - retrain xgb_limitdepth for 0.0s\n",
      "[flaml.automl.logger: 06-14 15:49:41] {2633} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=1.0, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.29999999999999993,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=0.9999999999999993, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=10, n_jobs=-1,\n",
      "              num_parallel_tree=None, objective='multi:softprob',\n",
      "              predictor=None, ...)\n",
      "[flaml.automl.logger: 06-14 15:49:41] {1941} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-14 15:49:41] {1942} INFO - Time taken to find the best model: 1.0082478523254395\n",
      "[[0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.9530079  0.0244897  0.02250246]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02060921 0.9005001  0.07889066]\n",
      " [0.02457794 0.95043    0.02499206]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.03117302 0.86136913 0.10745785]\n",
      " [0.02554155 0.94848657 0.02597191]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02866804 0.94218093 0.02915109]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02898548 0.9415406  0.02947388]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02898548 0.9415406  0.02947388]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.04973913 0.39211413 0.5581468 ]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02060921 0.9005001  0.07889066]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.0211989  0.92626595 0.05253515]\n",
      " [0.05105764 0.678746   0.2701964 ]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.0691848  0.45397815 0.476837  ]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.03117302 0.86136913 0.10745785]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02457794 0.95043    0.02499206]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02866804 0.94218093 0.02915109]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02187662 0.95587814 0.02224523]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.03064797 0.03477581 0.93457615]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.02237625 0.02485345 0.9527703 ]\n",
      " [0.02237625 0.02485345 0.9527703 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.06844829 0.29761684 0.63393486]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.02323865 0.03560167 0.94115967]\n",
      " [0.02237625 0.02485345 0.9527703 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.03438873 0.04146971 0.9241415 ]\n",
      " [0.03064797 0.03477581 0.93457615]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.02237625 0.02485345 0.9527703 ]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.08105624 0.2593941  0.65954965]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.03438873 0.04146971 0.9241415 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.0234161  0.02823771 0.94834626]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.04872553 0.12725613 0.82401836]\n",
      " [0.02239368 0.07066764 0.90693873]\n",
      " [0.02237625 0.02485345 0.9527703 ]\n",
      " [0.06136675 0.3099168  0.62871647]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.02237625 0.02485345 0.9527703 ]\n",
      " [0.0587506  0.19150174 0.7497477 ]\n",
      " [0.04448675 0.11160372 0.8439095 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.02237625 0.02485345 0.9527703 ]\n",
      " [0.04041081 0.2761848  0.6834044 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.02326307 0.03458828 0.9421486 ]\n",
      " [0.03064797 0.03477581 0.93457615]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.02231    0.02774045 0.9499495 ]\n",
      " [0.0234161  0.02823771 0.94834626]\n",
      " [0.02237625 0.02485345 0.9527703 ]\n",
      " [0.02229122 0.02855915 0.9491496 ]\n",
      " [0.03046732 0.0404652  0.9290675 ]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=1.0, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.29999999999999993,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=0.9999999999999993, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=10, n_jobs=-1,\n",
      "              num_parallel_tree=None, objective='multi:softprob',\n",
      "              predictor=None, ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 1,  # in seconds\n",
    "    \"metric\": 'accuracy',\n",
    "    \"task\": 'classification',\n",
    "    \"log_file_name\": \"iris.log\",\n",
    "}\n",
    "X_train, y_train = load_iris(return_X_y=True)\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,\n",
    "           **automl_settings)\n",
    "# Predict\n",
    "print(automl.predict_proba(X_train))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e64e04-752e-4647-b4fc-0aca6cd48da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
